---
title: 'Doing the Same Thing And ...'
date: 2019-11-27
categories:
   - general
---

# Doing the Same Thing And ...

You've heard the saying "the definition insanity is doing the same thing over and over again and expecting a different result." And I think you'll agree that this 'definition' is commonly true.  But, what about those times when you do the same thing each and every time and *get* a different result?  That, my friends, is the definition of randomness. And, it's far more common than you think.

Physicist Leonard Mlodinow, in his book *The Drunkard's Walk: How Randomness Rules Our Lives*, Psychologist <!-- more -->Dan Ariely, in *Predictably Irrational: The Hidden Forces That Shape Our Decisions*, Psychologist Daniel Kahneman, in *Thinking, Fast and Slow*, and a variety of others whose names I don't now recall, have all pointed to how often randomness injects itself into our lives without our ever realizing its influence. Not only is randomness more common than we realize, we actively reject the notion that something that occurs is simply a random event.  Rather, as Kahneman points out, we often create stories to "explain" what happens.  It seems we can't simply accept that most of the events in our lives are simply random events.

### Randomness, an Example

Take, for example, the manager that monitors sales in his store. He installed a contraption that counts the number of visitors to his store and uses that as a basis for determining the effectiveness of his sales staff.  Over the past few months he noted that sales tended to hang around 85% of visits.  That is, for every 100 visitors 85% of them became customers by purchasing something.  About four months ago, sales jumped by nearly 7% to 92%. The manager was ecstatic and praised his staff for their hard work.  They all kind of looked at each other because they really hadn't done anything differently. If asked, they would be unable to explain why the sales suddenly increased.  But the manager never asked; he was just happy to see the increase.  To the benefit of the sales staff, the manager assumed that the increase was the result of the employees' hard work.  That was his story to explain the increase.

The following month, though, sales were down a bit.  Still higher than the average of 85%, but not at that same nice 92%. It was closer to 87%.  He began to wonder what happened but didn't really say anything.  In the most recent month sales dropped again to 86% of visitors.  Now he is concerned that the staff are resting on their laurels and aren't working as hard to make sales and so he begins to suggest that they need to step it up. After all, if they can do 92% once, they shoud be able to maintain that.  Now, his story to explain the drop in sales is that the staff aren't working hard enough.

That manager does not understand how sales work. More specifically he doesn't understand the concept of randomness.

The sales staff did nothing different in order to achieve that nice 92%. It simply happened.  The steady drop back to 85% is simply what statisticians call *regression to the mean*.  Over time random events tend to return to the average.  There is variation in every process. This is most easily seen when a process, such as sales (yes, sales is a process), varies from its normal levels, particularly if the variation is sudden, unexpected, and unexplainable. If there is some clear explanation -- for example, a storm motivates more people to purchase generators than are normally purchased -- then the process itself is not random, though, of course, the cause of the variation (the storm) is.

Those involved in operations management know that variation is to be expected.  For example, let's suppose you manufacture chocolate chip cookies.  At each step of the process, there is some variation.  So, there might be slight differences in the quantities of ingredients added to each batch of dough, the amount of dough dispensed onto the conveyor that takes the cookies through the oven, and even the "doneness" of the cookies.  And, of course, not every cookie will have the same number of chocolate chips.  But, in general, all of those variations will be within an acceptable range. That acceptable range is defined by *control limits* -- upper and lower limits within which the process is allowed to vary. The idea is that even if all of the variations skewed to one extreme, the product would still meet quality control standards and every cookie will have some tasty chocolate chips in it. Only when the control limits are exceeded are corrective actions taken.

So, even though we follow the recipe for chocolate chip cookies every time, there is still a randomness to both the process and the outcome.

While this might be fairly easy to see in the cookies example, it's often less clear in other situations. Suppose you're shopping in the mall and you become aware that you've seen the same man several times, in several different stores. Your mind gets to work and you starting thinking, "is he following me?" That you cross paths several times while in the shopping center is largely a matter of chance -- randomness -- but because we don't really understand the role of randomness in our lives, we create stories to explain our observations (and allow our imaginations to run amok with nefarious ideas!)

Of course, as Kahneman points out, we don't like to accept the simple but true explanation that the variation was simple a random event. We're uncomfortable with that.  Instead, we create a story to explain the event.  When sales are up, the story is that the staff worked harder and deserves reward. When sales are down, the story is that the staff didn't work as hard and should be reprimanded and coaxed into working harder to re-establish those high sales.

### Making Stories 

The books I mentioned earlier all tell the same story: people are uncomfortable accepting that outcomes are most often random and, consequently, create stories that explain the results.  Think about the stock market. Despite what many would claim, the stock market is essentially a random process.  There are a great many factors that may influence the price of a stock on a given day, but over time the stock price is going to fluctuate fairly widely, regardless of whatever else is happening.  We know this is true simply by watching the price of a single stock. Watch the hour to hour changes in stock prices.  Watch the day-to-day and week-to-week changes.  How many of hte changes in the price of that stock can be difinitively linked to some action on the part of management? Not many, if any at all.  Why? Because the changes are random.  Over time stock prices tend to rise. But on a short-term basis there is a great deal of variablity in their prices.  All of that variability is the result of the randomness of the market. And nothing more.


### The Effect of Small Samples 

Recently, one of my colleagues was out of work for a bit.  On his return, he was assigned about 1/10th of the students he might normally have during the month.  When the data for the month were analyzed there was much ado about his having achieved a 100% pass rate (the team rate is about 85%).  He received much praise and acknowledgement for his hard work.  Did he deserve it?  Probably not. His situation describes the effect of small numbers -- the smaller the number in a sample, the more more extreme the results tend to be.  For him, the small number of students assigned to him resulted in a significant increase in his pass rate.  It is just as likely that his pass rate could have been 50%. 

If that last bit confused you, consider this: If you are teaching a class of 500 students, the effect of one student's score on the average score for the class is 0.002 (0.2%). So, the average score for the class is going to be the sum of the individual students' scores. However, if you're class only has 100 students in it, then the effect of one student on the overall class score is 0.01(1%) -- five times the impact on the overall average than the student who is one of 500.  

Now, let's reduce that even more.  Let's say your class only has 20 students. Each student has a 0.05  point (5%) impact on the overall score. 

Now let's look at how the change in a single students score from in score from 80% to 90% impacts the overall class average:

| Score/Students | 20 Students | 100 Students | 500 Students |
|:---------------------:|:-------------------:|:------------------:|:------------------:|
| 80%| avg: 75|avg: 75| avg: 75|
|90% | avg 75.5 | avg: 75.1|avg 75.02|

In this table it's easy to see how the number of students affects the impact that one student's grade has on the class average. Whether you're talking about the number of customers, the number of students, the number of cats, or the number of hotdogs as the subject of the statistical analysis, the simple fact is that the fewer subjects you include in your statistics the greater the individual's impact will be on the final result.  This means, of course, that with fewer subjects, you are more likely to see extreme results.

And that is what managers tend to overlook. Rather than considering the effect of smaller numbers on the results, they celebrate (or punish) the employee's 'effectiveness', even if the employee did nothing to bring about that outcome. The manager creates a story to explain the employee's performance even when there is no basis for the story.

